{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c01d4659-c72b-406e-a719-0e49fa85f015",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import subplots\n",
    "import patsy\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy import stats\n",
    "stats.chisqprob = lambda chisq, df: stats.chi2.sf(chisq, df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b808d25-b4a2-4255-b0b7-e769e9c1eab9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ISLP in c:\\users\\deepa\\anaconda3\\lib\\site-packages (0.3.21)\n",
      "Requirement already satisfied: numpy<1.25,>=1.7.1 in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from ISLP) (1.24.3)\n",
      "Requirement already satisfied: scipy>=0.9 in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from ISLP) (1.10.1)\n",
      "Requirement already satisfied: pandas<=1.9,>=0.20 in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from ISLP) (1.5.3)\n",
      "Requirement already satisfied: lxml in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from ISLP) (4.9.2)\n",
      "Requirement already satisfied: scikit-learn>=1.2 in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from ISLP) (1.3.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from ISLP) (1.2.0)\n",
      "Requirement already satisfied: statsmodels>=0.13 in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from ISLP) (0.14.0)\n",
      "Requirement already satisfied: lifelines in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from ISLP) (0.27.8)\n",
      "Requirement already satisfied: pygam in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from ISLP) (0.9.0)\n",
      "Requirement already satisfied: torch in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from ISLP) (2.1.0)\n",
      "Requirement already satisfied: pytorch-lightning in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from ISLP) (2.1.0)\n",
      "Requirement already satisfied: torchmetrics in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from ISLP) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from pandas<=1.9,>=0.20->ISLP) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from pandas<=1.9,>=0.20->ISLP) (2022.7)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from scikit-learn>=1.2->ISLP) (2.2.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from statsmodels>=0.13->ISLP) (0.5.3)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from statsmodels>=0.13->ISLP) (23.0)\n",
      "Requirement already satisfied: matplotlib>=3.0 in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from lifelines->ISLP) (3.7.1)\n",
      "Requirement already satisfied: autograd>=1.5 in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from lifelines->ISLP) (1.6.2)\n",
      "Requirement already satisfied: autograd-gamma>=0.3 in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from lifelines->ISLP) (0.5.0)\n",
      "Requirement already satisfied: formulaic>=0.2.2 in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from lifelines->ISLP) (0.6.6)\n",
      "Requirement already satisfied: progressbar2<5.0.0,>=4.2.0 in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from pygam->ISLP) (4.2.0)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from pytorch-lightning->ISLP) (4.65.0)\n",
      "Requirement already satisfied: PyYAML>=5.4 in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from pytorch-lightning->ISLP) (6.0)\n",
      "Requirement already satisfied: fsspec[http]>2021.06.0 in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from pytorch-lightning->ISLP) (2023.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from pytorch-lightning->ISLP) (4.7.1)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from pytorch-lightning->ISLP) (0.9.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from torch->ISLP) (3.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from torch->ISLP) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from torch->ISLP) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from torch->ISLP) (3.1.2)\n",
      "Requirement already satisfied: future>=0.15.2 in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from autograd>=1.5->lifelines->ISLP) (0.18.3)\n",
      "Requirement already satisfied: astor>=0.8 in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from formulaic>=0.2.2->lifelines->ISLP) (0.8.1)\n",
      "Requirement already satisfied: interface-meta>=1.2.0 in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from formulaic>=0.2.2->lifelines->ISLP) (1.3.0)\n",
      "Requirement already satisfied: wrapt>=1.0 in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from formulaic>=0.2.2->lifelines->ISLP) (1.14.1)\n",
      "Requirement already satisfied: requests in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from fsspec[http]>2021.06.0->pytorch-lightning->ISLP) (2.31.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from fsspec[http]>2021.06.0->pytorch-lightning->ISLP) (3.8.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from matplotlib>=3.0->lifelines->ISLP) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from matplotlib>=3.0->lifelines->ISLP) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from matplotlib>=3.0->lifelines->ISLP) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from matplotlib>=3.0->lifelines->ISLP) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from matplotlib>=3.0->lifelines->ISLP) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from matplotlib>=3.0->lifelines->ISLP) (3.0.9)\n",
      "Requirement already satisfied: six in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from patsy>=0.5.2->statsmodels>=0.13->ISLP) (1.16.0)\n",
      "Requirement already satisfied: python-utils>=3.0.0 in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from progressbar2<5.0.0,>=4.2.0->pygam->ISLP) (3.8.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from tqdm>=4.57.0->pytorch-lightning->ISLP) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from jinja2->torch->ISLP) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from sympy->torch->ISLP) (1.3.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->ISLP) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->ISLP) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->ISLP) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->ISLP) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->ISLP) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->ISLP) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->ISLP) (1.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning->ISLP) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning->ISLP) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\deepa\\anaconda3\\lib\\site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning->ISLP) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install ISLP\n",
    "from ISLP import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf72c44c-7362-458b-8bb2-0a97f0994f5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##set a random seed before beginning your analysis\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b475c9d5-2f62-4e3d-907a-271fbb7c44be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##getting data insight\n",
    "df = load_data(\"Default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53e856d5-5024-424e-a30e-5b1781eac878",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default</th>\n",
       "      <th>student</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>729.526495</td>\n",
       "      <td>44361.625074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>817.180407</td>\n",
       "      <td>12106.134700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>1073.549164</td>\n",
       "      <td>31767.138947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>529.250605</td>\n",
       "      <td>35704.493935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>785.655883</td>\n",
       "      <td>38463.495879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   default student      balance        income\n",
       "0        0      No   729.526495  44361.625074\n",
       "1        0     Yes   817.180407  12106.134700\n",
       "2        0      No  1073.549164  31767.138947\n",
       "3        0      No   529.250605  35704.493935\n",
       "4        0      No   785.655883  38463.495879"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['default'] = (df['default'] == 'Yes').astype('int')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fcb38b0-6693-4a01-8eed-05bd53b98e20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   default  10000 non-null  int32  \n",
      " 1   student  10000 non-null  object \n",
      " 2   balance  10000 non-null  float64\n",
      " 3   income   10000 non-null  float64\n",
      "dtypes: float64(2), int32(1), object(1)\n",
      "memory usage: 273.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6361c99-956b-46d3-8b3d-1e5dde386b7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.078948\n",
      "         Iterations 10\n",
      "Logistic Regression Coefficients: [[2.08089921e-05 5.64710291e-03]]\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                default   No. Observations:                10000\n",
      "Model:                          Logit   Df Residuals:                     9997\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Wed, 01 Nov 2023   Pseudo R-squ.:                  0.4594\n",
      "Time:                        22:33:25   Log-Likelihood:                -789.48\n",
      "converged:                       True   LL-Null:                       -1460.3\n",
      "Covariance Type:            nonrobust   LLR p-value:                4.541e-292\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept    -11.5405      0.435    -26.544      0.000     -12.393     -10.688\n",
      "income      2.081e-05   4.99e-06      4.174      0.000     1.1e-05    3.06e-05\n",
      "balance        0.0056      0.000     24.835      0.000       0.005       0.006\n",
      "==============================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.14 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n"
     ]
    }
   ],
   "source": [
    "###5.a) Fit a logistic regression model that uses income and balance to predict default.\n",
    "\n",
    "# Create a logistic regression model with a high regularization (C=1e6) and a small tolerance value\n",
    "logr_model = LogisticRegression(C=10**6, tol=1e-6)\n",
    "X = df[['income', 'balance']]\n",
    "y = df['default']\n",
    "logr_fit = logr_model.fit(X, y)\n",
    "logr_coefficients = logr_fit.coef_\n",
    "logistic_formula = 'default ~ income + balance'\n",
    "logistic_results = sm.Logit.from_formula(formula=logistic_formula, data=df).fit()\n",
    "logistic_summary = logistic_results.summary()\n",
    "# Print the results\n",
    "print(\"Logistic Regression Coefficients: {}\".format(logr_coefficients))\n",
    "print(logistic_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0db69c9-92fd-47d0-81e1-6f23899a0c54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##5.b Using the validation set approach, estimate the test error of this\n",
    "##model. In order to do this, you must perform the following steps:\n",
    "## i)Split the sample set into a training set and a validation set.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7b39fec-54ab-42af-a2b2-0db39961df6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00012769,  0.00049358]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##ii. Fit a multiple logistic regression model using only the training observations.\n",
    "logr_model = LogisticRegression()\n",
    "logr_model.fit(X_train, y_train)\n",
    "logr_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7727ab7d-e787-4af9-9109-505b48685167",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##iii. Obtain a prediction of default status for each individual in the validation set by computing the posterior probability of\n",
    "## default for that individual, and classifying the individual to the default category if the posterior probability is greater\n",
    "## than 0.5.\n",
    "posterior_prob = logr_model.predict_proba(X_test)\n",
    "default_prob = posterior_prob[:, 1]\n",
    "predictions = (default_prob > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ccd5ece0-c45e-498d-b552-909aa7941226",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Error: 0.03220\n"
     ]
    }
   ],
   "source": [
    "##Compute the validation set error, which is the fraction of the observations in the validation set that are misclassified.\n",
    "validation_set_error = 1 - (predictions == y_test).mean()\n",
    "print(f\"Validation Set Error: {validation_set_error:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "988b864f-2b81-4b2b-9a8e-a9de9d194f4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1 Validation Error: 0.03450\n",
      "Split 2 Validation Error: 0.02300\n",
      "Split 3 Validation Error: 0.03300\n"
     ]
    }
   ],
   "source": [
    "## 5.C)Repeat the process in (b) three times, using three different splits\n",
    "## of the observations into a training set and a validation set. Comment\n",
    "## on the results obtained. \n",
    "np.random.seed(42)\n",
    "\n",
    "validation_errors = []\n",
    "\n",
    "for loop in range(3):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    validation_error = 1 - accuracy_score(y_val, y_pred)\n",
    "    validation_errors.append(validation_error)\n",
    "\n",
    "for i, error in enumerate(validation_errors):\n",
    "    print(f'Split {i + 1} Validation Error: {error:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df80b43-7ee8-4904-a870-edf52b714716",
   "metadata": {},
   "source": [
    "Split 1 Validation Error: 0.03450: This indicates that the model's performance on the first validation split is relatively good. The validation error of 0.03450 suggests that the model correctly predicts the outcome for approximately 96.55% of the cases in the first validation set. It's a low error rate, which implies a high level of accuracy. \n",
    "\n",
    "Split 2 Validation Error: 0.02300: The second validation error is even lower at 0.02300, indicating a very accurate model performance. In this case, the model correctly predicts the outcome for approximately 97.70% of the cases in the second validation set. This is an even better performance than in the first split.\n",
    "\n",
    "Split 3 Validation Error: 0.03300: The third validation error is slightly higher than the second split but still relatively low at 0.03300. This implies that the model correctly predicts the outcome for around 96.70% of the cases in the third validation set. While it's slightly worse than the second split, it's still a good level of accuracy.\n",
    "\n",
    "Overall, the results suggest that the model is performing well in terms of classification accuracy across different validation splits. The model seems to have a consistent and low error rate in each split, indicating that it generalizes well to new data. ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "29098ce4-ae13-461c-9405-9795a7dcd6a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1 Validation Error (with Student): 0.02800\n",
      "Split 2 Validation Error (with Student): 0.03467\n",
      "Split 3 Validation Error (with Student): 0.03233\n"
     ]
    }
   ],
   "source": [
    "## (d) Now consider a logistic regression model that predicts the probability of default using income, balance, and a dummy variable\n",
    "## for student. Estimate the test error for this model using the validation set approach. Comment on whether or not including a\n",
    "## dummy variable for student leads to a reduction in the test error rate.\n",
    "np.random.seed(32)\n",
    "df['student_dummy'] = (df['student'] == 'Yes').astype(int)\n",
    "\n",
    "X = df[['income', 'balance', 'student_dummy']]\n",
    "y = df['default']\n",
    "\n",
    "validation_errors_student = []\n",
    "\n",
    "for loop in range(3):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    validation_error = 1 - accuracy_score(y_val, y_pred)\n",
    "    validation_errors_student.append(validation_error)\n",
    "\n",
    "for i, error in enumerate(validation_errors_student):\n",
    "    print(f'Split {i + 1} Validation Error (with Student): {error:.5f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63709764-1aee-4585-8e20-3624884044f9",
   "metadata": {},
   "source": [
    "In Split 1, including the \"student\" dummy variable reduces the error rate from 0.03450 to 0.02800. This indicates a reduction in test error when including the \"student\" variable.\n",
    "\n",
    "In Split 2, including the \"student\" variable results in an increase in error rate from 0.02300 to 0.03467. In this case, the test error rate increases when including the \"student\" variable.\n",
    "\n",
    "In Split 3, the error rate remains relatively similar when including the \"student\" variable (0.03300 without \"student\" vs. 0.03233 with \"student\").\n",
    "\n",
    "The effect of including the \"student\" dummy variable on the test error rate is mixed. It seems to reduce the error in some splits but not in others. The impact of adding this variable can depend on the specific dataset and how it relates to the target variable (\"default\" in this case). It's important to consider both the statistical significance and the practical significance of including additional features in your model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c013c8-15a0-469b-b297-9b7b7d1f87a8",
   "metadata": {},
   "source": [
    "question 5.6) We continue to consider the use of a logistic regression model to\n",
    "predict the probability of default using income and balance on the\n",
    "Default data set. In particular, we will now compute estimates for the\n",
    "standard errors of the income and balance logistic regression coefficients\n",
    "in two different ways: (1) using the bootstrap, and (2) using the\n",
    "standard formula for computing the standard errors in the sm.GLM()\n",
    "function. Do not forget to set a random seed before beginning your\n",
    "analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aeab355c-d392-4e71-ac5b-d221670b41e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Generalized Linear Model Regression Results                        \n",
      "===========================================================================================\n",
      "Dep. Variable:     ['default[No]', 'default[Yes]']   No. Observations:                10000\n",
      "Model:                                         GLM   Df Residuals:                     9997\n",
      "Model Family:                             Binomial   Df Model:                            2\n",
      "Link Function:                               Logit   Scale:                          1.0000\n",
      "Method:                                       IRLS   Log-Likelihood:                -789.48\n",
      "Date:                             Wed, 01 Nov 2023   Deviance:                       1579.0\n",
      "Time:                                     23:54:38   Pearson chi2:                 6.95e+03\n",
      "No. Iterations:                                  9   Pseudo R-squ. (CS):             0.1256\n",
      "Covariance Type:                         nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     11.5405      0.435     26.544      0.000      10.688      12.393\n",
      "income     -2.081e-05   4.99e-06     -4.174      0.000   -3.06e-05    -1.1e-05\n",
      "balance       -0.0056      0.000    -24.835      0.000      -0.006      -0.005\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "##(a) Using the summarize() and sm.GLM() functions, determine the estimated standard errors for the coefficients associated with\n",
    "##income and balance in a multiple logistic regression model that uses both predictors.\n",
    "df = load_data(\"Default\")\n",
    "np.random.seed(32)\n",
    "model2 = smf.glm(formula='default ~ income + balance', data=df, family=sm.families.Binomial())\n",
    "results = model2.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913129b9-4f30-44fc-9b51-7b1dc98a78ef",
   "metadata": {},
   "source": [
    "the estimated standard errors for the coefficients is 4.99e-06"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dd5fe8-db0c-4956-831b-275f6a9b102a",
   "metadata": {},
   "source": [
    "(b) Write a function, boot_fn(), that takes as input the Default data set as well as an index of the observations, and that outputs\n",
    "the coefficient estimates for income and balance in the multiple\n",
    "logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f67c51e1-d5a9-43d3-a6ac-d4897bc8f0b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the coefficient estimates for income and balance: [2.997799198826917e-05, 0.005880971047949065]\n"
     ]
    }
   ],
   "source": [
    "df = load_data(\"Default\")\n",
    "def boot_fn(data, indices):\n",
    "    bootstrapped_data = data.iloc[indices]\n",
    "    X = bootstrapped_data[['income', 'balance']]\n",
    "    X = sm.add_constant(X)\n",
    "    y = (bootstrapped_data['default'] == 'Yes').astype(int)\n",
    "    model = sm.GLM(y, X, family=sm.families.Binomial())\n",
    "    results = model.fit()\n",
    "    coef_income = results.params[1]\n",
    "    coef_balance = results.params[2]\n",
    "    return [coef_income, coef_balance]\n",
    "random_indices = np.random.choice(len(df), len(df), replace=True)\n",
    "\n",
    "print('the coefficient estimates for income and balance:', boot_fn(df,random_indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83e7136-c5eb-4525-9c97-016c8d820105",
   "metadata": {},
   "source": [
    "(c) Following the bootstrap example in the lab, use your boot_fn()\n",
    "function to estimate the standard errors of the logistic regression\n",
    "coefficients for income and balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "dd053d69-cfda-416f-a795-871a6feb48fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimated Standard Error for Income: 4.6819982042439346e-06\n",
      "estimated Standard Error for Balance: 0.0002264350150464406\n"
     ]
    }
   ],
   "source": [
    "## to call boot function n times we defined n as 1000\n",
    "df = load_data(\"Default\")\n",
    "\n",
    "n = 1000\n",
    "coefficient_estimates = []\n",
    "\n",
    "for _ in range(n):\n",
    "    \n",
    "    random_indices = np.random.choice(len(df), len(df), replace=True)  \n",
    "    \n",
    "    coefficients = boot_fn(df, random_indices)\n",
    "    coefficient_estimates.append(coefficients)\n",
    "\n",
    "bootstrap_std_errors = np.std(coefficient_estimates, axis=0)\n",
    "\n",
    "\n",
    "income_sd_error = bootstrap_std_errors[0]\n",
    "balance_sd_error = bootstrap_std_errors[1]\n",
    "\n",
    "print(\"estimated Standard Error for Income:\", income_sd_error)\n",
    "print(\"estimated Standard Error for Balance:\", balance_sd_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec5cdb5-9d85-4b86-830f-d72043a66484",
   "metadata": {},
   "source": [
    "(d) Comment on the estimated standard errors obtained using the\n",
    "sm.GLM() function and using the bootstrap."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75991341-452c-473e-9916-6e9b896f6e22",
   "metadata": {},
   "source": [
    "Both method provides almost similar the standard errors indicating that the bootstrap method is effectively approximate the same standard errors as calculated using more traditional methods.\n",
    "\n",
    "Still always need to consider that calculation of standard error depend on the nature of dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd58d7d-7706-4088-9e58-feabcbb4285b",
   "metadata": {},
   "source": [
    "5.7 In Sections 5.1.2 and 5.1.3, we saw that the cross_validate() function\n",
    "can be used in order to compute the LOOCV test error estimate.\n",
    "Alternatively, one could compute those quantities using just sm.GLM()\n",
    "and the predict() method of the fitted model within a for loop. You\n",
    "will now take this approach in order to compute the LOOCV error\n",
    "for a simple logistic regression model on the Weekly data set. Recall\n",
    "that in the context of classification problems, the LOOCV error is\n",
    "given in (5.4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "364b92ca-1c3e-49e2-938b-61854a8b700c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import glm\n",
    "from statsmodels.genmod.families import Binomial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b34b2fb-c1d9-4b24-b507-9f09332bcfb3",
   "metadata": {},
   "source": [
    "(a) Fit a logistic regression model that predicts Direction using Lag1\n",
    "and Lag2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "060ed3a7-4884-4969-ba0f-8df4a2a58355",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Lag1</th>\n",
       "      <th>Lag2</th>\n",
       "      <th>Lag3</th>\n",
       "      <th>Lag4</th>\n",
       "      <th>Lag5</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Today</th>\n",
       "      <th>Direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>-3.936</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>-3.484</td>\n",
       "      <td>0.154976</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>-3.936</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.148574</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>-3.936</td>\n",
       "      <td>0.159837</td>\n",
       "      <td>3.514</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990</td>\n",
       "      <td>3.514</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>0.161630</td>\n",
       "      <td>0.712</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990</td>\n",
       "      <td>0.712</td>\n",
       "      <td>3.514</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.153728</td>\n",
       "      <td>1.178</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year   Lag1   Lag2   Lag3   Lag4   Lag5    Volume  Today Direction\n",
       "0  1990  0.816  1.572 -3.936 -0.229 -3.484  0.154976 -0.270      Down\n",
       "1  1990 -0.270  0.816  1.572 -3.936 -0.229  0.148574 -2.576      Down\n",
       "2  1990 -2.576 -0.270  0.816  1.572 -3.936  0.159837  3.514        Up\n",
       "3  1990  3.514 -2.576 -0.270  0.816  1.572  0.161630  0.712        Up\n",
       "4  1990  0.712  3.514 -2.576 -0.270  0.816  0.153728  1.178        Up"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = load_data(\"Weekly\")\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b0c60d2-b950-4d5f-a120-7195d6a52ecc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:              Direction   No. Observations:                 1089\n",
      "Model:                            GLM   Df Residuals:                     1086\n",
      "Model Family:                Binomial   Df Model:                            2\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -744.11\n",
      "Date:                Thu, 02 Nov 2023   Deviance:                       1488.2\n",
      "Time:                        01:37:57   Pearson chi2:                 1.09e+03\n",
      "No. Iterations:                     4   Pseudo R-squ. (CS):           0.007303\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.2212      0.061      3.599      0.000       0.101       0.342\n",
      "Lag1          -0.0387      0.026     -1.477      0.140      -0.090       0.013\n",
      "Lag2           0.0602      0.027      2.270      0.023       0.008       0.112\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "df1['Direction'] = df1['Direction'].map({'Up': 1, 'Down': 0})\n",
    "\n",
    "model = glm('Direction ~ Lag1 + Lag2', data=df1, family=Binomial()).fit()\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0994d3-0dd3-4ce4-8e39-11bc381900af",
   "metadata": {},
   "source": [
    "(b) Fit a logistic regression model that predicts Direction using Lag1\n",
    "and Lag2 using all but the first observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fdffbc4-af20-4f7d-9251-b9b750ad46b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:              Direction   No. Observations:                 1088\n",
      "Model:                            GLM   Df Residuals:                     1085\n",
      "Model Family:                Binomial   Df Model:                            2\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -743.26\n",
      "Date:                Thu, 02 Nov 2023   Deviance:                       1486.5\n",
      "Time:                        01:38:02   Pearson chi2:                 1.09e+03\n",
      "No. Iterations:                     4   Pseudo R-squ. (CS):           0.007373\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.2232      0.061      3.630      0.000       0.103       0.344\n",
      "Lag1          -0.0384      0.026     -1.466      0.143      -0.090       0.013\n",
      "Lag2           0.0608      0.027      2.291      0.022       0.009       0.113\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "data_excluding_first = df1.iloc[1:]\n",
    "\n",
    "new_model = glm('Direction ~ Lag1 + Lag2', data=data_excluding_first, family=Binomial()).fit()\n",
    "\n",
    "print(new_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0098a0-a956-43c4-ae8b-84134a76ec3c",
   "metadata": {},
   "source": [
    "(c) Use the model from (b) to predict the direction of the first observation.\n",
    "You can do this by predicting that the first observation\n",
    "will go up if P(Direction = \"Up\"|Lag1, Lag2) > 0.5. Was this\n",
    "observation correctly classified?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c6555ec-307c-4947-95b4-9c4138fa19f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Direction: Up\n",
      "Actual Direction: Down\n",
      "Correctly Classified? False\n"
     ]
    }
   ],
   "source": [
    "first_observation = df1.iloc[0]\n",
    "lag1 = first_observation['Lag1']\n",
    "lag2 = first_observation['Lag2']\n",
    "\n",
    "\n",
    "first_observation_pred = new_model.predict({'Lag1': lag1, 'Lag2': lag2})\n",
    "\n",
    "\n",
    "predicted_direction = 1 if first_observation_pred.values[0] > 0.5 else 0\n",
    "\n",
    "# prediction comparision\n",
    "actual_direction = first_observation['Direction']\n",
    "correctly_classified = predicted_direction == actual_direction\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Predicted Direction: {'Up' if predicted_direction else 'Down'}\")\n",
    "print(f\"Actual Direction: {'Up' if actual_direction else 'Down'}\")\n",
    "print(f\"Correctly Classified? {correctly_classified}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfb5b8a-e108-42f0-8c57-69cd2955c9f1",
   "metadata": {},
   "source": [
    "(d) Write a for loop from i = 1 to i = n, where n is the number of\n",
    "observations in the data set, that performs each of the following\n",
    "steps:\n",
    "\n",
    "i. Fit a logistic regression model using all but the ith observation\n",
    "to predict Direction using Lag1 and Lag2.\n",
    "ii. Compute the posterior probability of the market moving up\n",
    "for the ith observation.\n",
    "iii. Use the posterior probability for the ith observation in order\n",
    "to predict whether or not the market moves up.\n",
    "iv. Determine whether or not an error was made in predicting\n",
    "the direction for the ith observation. If an error was made,\n",
    "then indicate this as a 1, and otherwise indicate it as a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "798225c4-a92a-432a-ac91-56ea7f8b183b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total errors: 490\n"
     ]
    }
   ],
   "source": [
    "n = len(df1)\n",
    "errors = []\n",
    "\n",
    "for i in range(n):\n",
    "    training_df = df1.drop(df1.index[i])\n",
    "    testing_df = df1.iloc[i]\n",
    "    \n",
    "    # logistic regression model\n",
    "    new_model2 = glm('Direction ~ Lag1 + Lag2', data=training_df, family=Binomial()).fit()\n",
    "    \n",
    "    # Compute the posterior probability of the market moving up for the ith observation\n",
    "    predicted_prob = new_model2.predict({'Lag1': testing_df['Lag1'], 'Lag2': testing_df['Lag2']}).values[0]\n",
    "    \n",
    "    # Use the posterior probability for the ith observation in order to predict whether or not the market moves up\n",
    "    predicted_direction = 1 if predicted_prob > 0.5 else 0\n",
    "    \n",
    "    # Determine whether or not an error was made in predicting the direction for the ith observation. If an error was made, then indicate this as a 1, and otherwise indicate it as a 0.\n",
    "    actual_direction = testing_df['Direction']\n",
    "    error = 1 if predicted_direction != actual_direction else 0\n",
    "    \n",
    "    errors.append(error)\n",
    "\n",
    "print(f\"Total errors: {sum(errors)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce2963d-6c20-4e8a-860b-62d3023568d2",
   "metadata": {},
   "source": [
    "(e) Take the average of the n numbers obtained in (d)iv in order to\n",
    "obtain the LOOCV estimate for the test error. Comment on the\n",
    "results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a73dc960-d9c5-481f-b75b-42791f6b65f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The LOOCV estimate for the test error: 0.44995408631772266\n"
     ]
    }
   ],
   "source": [
    "loocv_estimate_for_test_error = sum(errors) / len(df1)\n",
    "\n",
    "print(\"The LOOCV estimate for the test error:\", loocv_estimate_for_test_error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be57fff3-b698-4d6b-8fed-d3f660cc060a",
   "metadata": {},
   "source": [
    "LOOCV estimate is nearly 45% which is high indicating that model prediction using lag1 and lag2 are not highly accurate so its not that remarkable performance over random guessing approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af777dc2-50ee-4e3b-a304-6ce6d6525622",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
